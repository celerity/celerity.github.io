"use strict";(self.webpackChunk=self.webpackChunk||[]).push([[340],{6728:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>l,contentTitle:()=>a,default:()=>h,frontMatter:()=>o,metadata:()=>s,toc:()=>c});var i=n(4848),r=n(8453);const o={id:"tutorial",title:"Complete Application Tutorial",sidebar_label:"Tutorial"},a=void 0,s={id:"tutorial",title:"Complete Application Tutorial",description:"This section gives a walkthrough of how a simple Celerity application can be",source:"@site/celerity-runtime/docs/tutorial.md",sourceDirName:".",slug:"/tutorial",permalink:"/docs/tutorial",draft:!1,unlisted:!1,tags:[],version:"current",lastUpdatedBy:"Fabian Knorr",lastUpdatedAt:1689266617e3,frontMatter:{id:"tutorial",title:"Complete Application Tutorial",sidebar_label:"Tutorial"},sidebar:"docs",previous:{title:"Installation",permalink:"/docs/installation"},next:{title:"Range Mappers",permalink:"/docs/range-mappers"}},l={},c=[{value:"Setting Up a CMake Project",id:"setting-up-a-cmake-project",level:2},{value:"Image Handling Boilerplate",id:"image-handling-boilerplate",level:2},{value:"Celerity Queue and Buffers",id:"celerity-queue-and-buffers",level:2},{value:"Detecting Those Edges",id:"detecting-those-edges",level:2},{value:"Saving The Result",id:"saving-the-result",level:2},{value:"Running The Application",id:"running-the-application",level:2}];function d(e){const t={a:"a",blockquote:"blockquote",code:"code",em:"em",h2:"h2",img:"img",p:"p",pre:"pre",strong:"strong",...(0,r.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsxs)(t.p,{children:["This section gives a walkthrough of how a simple Celerity application can be\nset up from start to finish. Before you begin, make sure you have ",(0,i.jsx)(t.a,{href:"/docs/installation",children:"built and\ninstalled"})," Celerity and all of its dependencies."]}),"\n",(0,i.jsx)(t.p,{children:"We are going to implement a simple image processing kernel that performs edge\ndetection on an input image and writes the resulting image back to the\nfilesystem. Here you can see how a result might look (white parts):"}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.img,{src:n(6569).A+"",width:"784",height:"318"})}),"\n",(0,i.jsxs)(t.p,{children:[(0,i.jsx)(t.a,{href:"https://commons.wikimedia.org/wiki/File:Wiesenknopf_Bl%C3%BCte_6260037-PSD-PSD.jpg",children:"Original image"})," by Reinhold M\xf6ller (CC-BY-SA 4.0)."]}),"\n",(0,i.jsx)(t.h2,{id:"setting-up-a-cmake-project",children:"Setting Up a CMake Project"}),"\n",(0,i.jsxs)(t.p,{children:["The first thing you typically want to do when writing a Celerity application\nis to set up a CMake project. For this, create a new folder for your project\nand in it create a file ",(0,i.jsx)(t.code,{children:"CMakeLists.txt"})," with the following contents:"]}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-cmake",children:"cmake_minimum_required(VERSION 3.13)\nproject(celerity_edge_detection)\n\nfind_package(Celerity CONFIG REQUIRED)\n\nadd_executable(edge_detection edge_detection.cpp)\nadd_celerity_to_target(TARGET edge_detection SOURCES edge_detection.cpp)\n"})}),"\n",(0,i.jsxs)(t.p,{children:["With this simple CMake configuration file we've created a new executable\ncalled ",(0,i.jsx)(t.code,{children:"edge_detection"})," that links to Celerity. The important section is the\ncall to ",(0,i.jsx)(t.code,{children:"add_celerity_to_target"}),", where we specify both the target that we\nwant to turn into a Celerity executable, as well as all source files that\nshould be compiled for accelerator execution."]}),"\n",(0,i.jsxs)(t.p,{children:["Create an empty file ",(0,i.jsx)(t.code,{children:"edge_detection.cpp"})," next to your ",(0,i.jsx)(t.code,{children:"CMakeLists.txt"}),".\nThen, create a new folder ",(0,i.jsx)(t.code,{children:"build"})," inside your project directory, navigate\ninto it and simply run ",(0,i.jsx)(t.code,{children:"cmake .."})," to configure your project. Just as during\n",(0,i.jsx)(t.a,{href:"/docs/installation",children:"installation"}),", you might have to provide some additional\nparameters to CMake in order for it to find and/or configure Celerity and its\ndependencies."]}),"\n",(0,i.jsx)(t.h2,{id:"image-handling-boilerplate",children:"Image Handling Boilerplate"}),"\n",(0,i.jsxs)(t.p,{children:["We're going to start by adding the necessary code to load (and later save) an\nimage file. To this end, we'll use the ",(0,i.jsx)(t.a,{href:"https://github.com/nothings/stb",children:"stb"}),"\nsingle file libraries. Download ",(0,i.jsx)(t.code,{children:"stb_image.h"})," and ",(0,i.jsx)(t.code,{children:"stb_image_write.h"})," from\nGitHub and drop them next to our source file."]}),"\n",(0,i.jsxs)(t.p,{children:["Next, add the following code to ",(0,i.jsx)(t.code,{children:"edge_detection.cpp"}),":"]}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-cpp",children:'#include <cstdlib>\n\n#define STB_IMAGE_IMPLEMENTATION\n#include "stb_image.h"\n#define STB_IMAGE_WRITE_IMPLEMENTATION\n#include "stb_image_write.h"\n\nint main(int argc, char* argv[]) {\n    if(argc != 2) return EXIT_FAILURE;\n    int img_width, img_height;\n    uint8_t* img_data = stbi_load(argv[1], &img_width, &img_height, nullptr, 1);\n    stbi_image_free(img_data);\n    return EXIT_SUCCESS;\n}\n'})}),"\n",(0,i.jsxs)(t.p,{children:["First we check that the user provided an image file name and if so, we load\nthe corresponding file using ",(0,i.jsx)(t.code,{children:"stbi_load()"}),". The last parameter tells stb that\nwe want to load the image as grayscale. The result is then stored in an array\nof ",(0,i.jsx)(t.code,{children:"uint8_t"}),", which consists of ",(0,i.jsx)(t.code,{children:"img_height"})," lines of size ",(0,i.jsx)(t.code,{children:"img_width"})," each.\nWe then immediately free the image again and exit."]}),"\n",(0,i.jsxs)(t.blockquote,{children:["\n",(0,i.jsx)(t.p,{children:"Now might be a good time to compile and run the program to make sure\neverything works so far."}),"\n"]}),"\n",(0,i.jsx)(t.h2,{id:"celerity-queue-and-buffers",children:"Celerity Queue and Buffers"}),"\n",(0,i.jsxs)(t.p,{children:["With everything set up, we can now begin to implement the Celerity portion of\nour application. The first thing that we will require in any Celerity program\nis the ",(0,i.jsx)(t.strong,{children:"distributed queue"}),". Similar to how a SYCL queue allows you to\nsubmit work to a compute device, the Celerity distributed queue allows you to\nsubmit work to the distributed runtime system -- which will subsequently be\nsplit transparently across all available worker nodes."]}),"\n",(0,i.jsxs)(t.p,{children:["Additionally, we will require ",(0,i.jsx)(t.strong,{children:"buffers"})," to store our input image as well as\nthe resulting edge-detected image in a way that can be efficiently accessed\nby the GPU. Let's create our two buffers and the distributed queue now:"]}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-cpp",children:"#include <celerity/celerity.h>\n...\nuint8_t* img_data = stbi_load(argv[1], &img_width, &img_height, nullptr, 1);\ncelerity::buffer<uint8_t, 2> input_buf(img_data, celerity::range<2>(img_height, img_width));\nstbi_image_free(img_data);\ncelerity::buffer<uint8_t, 2> edge_buf(celerity::range<2>(img_height, img_width));\ncelerity::distr_queue queue;\n...\n"})}),"\n",(0,i.jsxs)(t.p,{children:["With this we've created a couple of two-dimensional buffers, ",(0,i.jsx)(t.code,{children:"input_buf"})," and\n",(0,i.jsx)(t.code,{children:"edge_buf"}),", that both store values of type ",(0,i.jsx)(t.code,{children:"uint8_t"})," and are of size\n",(0,i.jsx)(t.code,{children:"(img_height, img_width)"}),". Notice that we initialize ",(0,i.jsx)(t.code,{children:"input_buf"})," using the\nimage data that we've just read. We can then immediately free the raw image,\nas we no longer need it. ",(0,i.jsx)(t.code,{children:"edge_buf"})," on the other hand is not being\ninitialized with any existing data, as it will be used to store the result of\nour image processing kernel."]}),"\n",(0,i.jsx)(t.h2,{id:"detecting-those-edges",children:"Detecting Those Edges"}),"\n",(0,i.jsxs)(t.p,{children:["Now we are ready to do the actual edge detection. For this we will write a\n",(0,i.jsx)(t.strong,{children:"kernel function"})," that will be executed on one or more GPUs. The way kernels\nare specified in Celerity is very similar to how it is done in SYCL:"]}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-cpp",children:"queue.submit([&](celerity::handler& cgh) {\n    // TODO: Buffer accessors\n    cgh.parallel_for<class MyEdgeDetectionKernel>(\n        celerity::range<2>(img_height - 2, img_width - 2),\n        celerity::id<2>(1, 1),\n        [=](celerity::item<2> item) {\n            // TODO: Kernel code\n        }\n    );\n});\n"})}),"\n",(0,i.jsxs)(t.p,{children:["We call ",(0,i.jsx)(t.code,{children:"queue.submit()"})," to inform the Celerity runtime that we want to\nexecute a new kernel function. As an argument, we pass a so-called ",(0,i.jsx)(t.strong,{children:"command\ngroup"}),"; a C++11 lambda function. Command groups themselves are not being\nexecuted on an accelerator. Instead, they serve as a way of tying kernels\nto buffers, informing the runtime system exactly how we plan to access\ndifferent buffers from within our kernels. This is done through ",(0,i.jsx)(t.strong,{children:"buffer\naccessors"}),", which we will create in a minute."]}),"\n",(0,i.jsxs)(t.p,{children:["The actual kernel code that will be executed on our compute device(s) resides\nwithin the last argument to the ",(0,i.jsx)(t.code,{children:"celerity::handler::parallel_for"})," function -\nagain concisely written as a lambda expression. Let us continue by fleshing\nout the kernel code. Replace the TODO with the following code:"]}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-cpp",children:"int sum = r_input[{item[0] + 1, item[1]}] + r_input[{item[0] - 1, item[1]}]\n        + r_input[{item[0], item[1] + 1}] + r_input[{item[0], item[1] - 1}];\nw_edge[item] = 255 - std::max(0, sum - (4 * r_input[item]));\n"})}),"\n",(0,i.jsxs)(t.p,{children:["This kernel computes a ",(0,i.jsx)(t.a,{href:"https://en.wikipedia.org/wiki/Discrete_Laplace_operator",children:"discrete Laplace\nfilter"})," - a simple\ntype of edge detection filter - by summing up the four pixel values along the\nmain axes surrounding the current result pixel and computing the difference\nto the current pixel value. We then subtract the resulting value from the\nmaximum value a ",(0,i.jsx)(t.code,{children:"uint8_t"})," can store (255) in order to get a white image with\nblack edges. The current pixel position is described by the\n",(0,i.jsx)(t.code,{children:"celerity::item<2>"})," we receive as an argument to our kernel function. This\ntwo-dimensional item corresponds to a ",(0,i.jsx)(t.code,{children:"y/x"})," position in our input and output\nimages and can be used to index into the respective buffers. However, we're\nnot using the buffers directly; instead we are indexing into the\naforementioned buffer accessors. Let's create these now - replace the TODO\nbefore the kernel function with the following:"]}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-cpp",children:"celerity::accessor r_input{input_buf, cgh, celerity::access::neighborhood{1, 1}, celerity::read_only};\ncelerity::accessor w_edge{edge_buf, cgh, celerity::access::one_to_one{}, celerity::write_only, celerity::no_init};\n"})}),"\n",(0,i.jsxs)(t.p,{children:["If you have worked with SYCL before, these buffer accessors will look\nfamiliar to you. Accessors tie kernels to the data they operate on by declaring\nthe type of access that we want to perform: We want to ",(0,i.jsx)(t.em,{children:"read"})," from our\n",(0,i.jsx)(t.code,{children:"input_buf"}),", and want to ",(0,i.jsx)(t.em,{children:"write"})," to our ",(0,i.jsx)(t.code,{children:"edge_buf"}),". Additionally, we do not care\nat all about preserving any of the previous contents of ",(0,i.jsx)(t.code,{children:"edge_buf"}),", which is why\nwe choose to discard them by also passing the ",(0,i.jsx)(t.code,{children:"celerity::no_init"})," property."]}),"\n",(0,i.jsxs)(t.p,{children:["So far everything works exactly as it would in a SYCL application. However,\nthere is an additional parameter passed into the ",(0,i.jsx)(t.code,{children:"accessor"})," constructor that is\nnot present in its SYCL counterpart. In fact, this parameter represents one of\nCelerity's most important API additions: While access modes (such as ",(0,i.jsx)(t.code,{children:"read"})," and\n",(0,i.jsx)(t.code,{children:"write"}),") tell the runtime system how a kernel intends to access a buffer, they\ndo not convey any information about ",(0,i.jsx)(t.em,{children:"where"})," a kernel will access said buffer.\nIn order for Celerity to be able to split a single kernel execution across\npotentially many different worker nodes, it needs to know how each of those\n",(0,i.jsx)(t.strong,{children:"kernel chunks"})," will interact with the input and output buffers of a kernel\n-- i.e., which node requires which parts of the input, and produces which\nparts of the output. This is where Celerity's so-called ",(0,i.jsx)(t.strong,{children:"range mappers"})," come\ninto play."]}),"\n",(0,i.jsxs)(t.p,{children:["Let us first discuss the range mapper for ",(0,i.jsx)(t.code,{children:"edge_buf"}),", as it represents the\nsimpler of the two cases. Looking at the kernel function, you can see that\nfor each invocation of the kernel -- i.e., for each work item, we only ever\naccess the output buffer once: at exactly the current location represented by\nthe ",(0,i.jsx)(t.code,{children:"item"}),". This means there exists a one-to-one mapping of the kernel index\nand the accessed buffer index. For this reason we pass a\n",(0,i.jsx)(t.code,{children:"celerity::access::one_to_one"})," range mapper (which means that kernel and\nbuffer need to have the same dimensionality and size)."]}),"\n",(0,i.jsxs)(t.p,{children:["The range mapper for our ",(0,i.jsx)(t.code,{children:"input_buf"})," is a bit more complicated, but not by\nmuch: Remember that for computing the Laplace filter, we are summing up the\npixel values of the four surrounding pixels along the main axes and\ncalculating the difference to the current pixel. This means that in addition\nto reading the pixel value associated with each item, each kernel thread also\nreads a 1-pixel ",(0,i.jsx)(t.em,{children:"neighborhood"})," around the current item. This being another\nvery common pattern, it can be expressed with the\n",(0,i.jsx)(t.code,{children:"celerity::access::neighborhood"})," range mapper. The parameters ",(0,i.jsx)(t.code,{children:"(1, 1)"}),"\nsignify that we want to access a 1-item boundary in each dimension\nsurrounding the current work item."]}),"\n",(0,i.jsxs)(t.blockquote,{children:["\n",(0,i.jsxs)(t.p,{children:["While we are using built-in range mappers provided by the Celerity API,\nthey can in fact also be user-defined functions! For more information on\nrange mappers, see ",(0,i.jsx)(t.a,{href:"/docs/range-mappers",children:"Range Mappers"}),"."]}),"\n"]}),"\n",(0,i.jsxs)(t.p,{children:["Lastly, there are two more things of note for the call to ",(0,i.jsx)(t.code,{children:"parallel_for"}),": The\nfirst is the ",(0,i.jsx)(t.strong,{children:"kernel name"}),". Just like in SYCL, each kernel function in\nCelerity may have a unique name in the form of a template type parameter.\nHere we chose ",(0,i.jsx)(t.code,{children:"MyEdgeDetectionKernel"}),", but this can be anything you like."]}),"\n",(0,i.jsxs)(t.blockquote,{children:["\n",(0,i.jsx)(t.p,{children:"Kernel names used to be mandatory in SYCL 1.2.1 but have since become optional."}),"\n"]}),"\n",(0,i.jsxs)(t.p,{children:["Finally, the first two parameters to the ",(0,i.jsx)(t.code,{children:"parallel_for"})," function tell\nCelerity how many individual GPU threads (or work items) we want to execute.\nIn our case we want to execute one thread for each pixel of our image, except\nfor a 1-pixel border on the outside of the image - which is why we subtract\n2 from our image size in both dimensions and additionally specify the\nexecution offset of ",(0,i.jsx)(t.code,{children:"(1, 1)"}),". ",(0,i.jsx)(t.em,{children:"Why"})," this is a good idea is left as an\nexercise for the reader ;-)."]}),"\n",(0,i.jsx)(t.p,{children:"...and that's it, we successfully submitted a kernel to compute an edge\ndetection filter on our input image and store the result in an output buffer.\nThe only thing that remains to do now is to save the resulting image back to\na file."}),"\n",(0,i.jsx)(t.h2,{id:"saving-the-result",children:"Saving The Result"}),"\n",(0,i.jsxs)(t.p,{children:["To write the image resulting from our kernel execution back to a file, we need\nto pass the contents of ",(0,i.jsx)(t.code,{children:"edge_buf"})," back to the host. Similar to SYCL 2020,\nCelerity offers ",(0,i.jsx)(t.em,{children:"host tasks"})," for this purpose. In the distributed memory setting,\nwe opt for the simple solution of transferring the entire image to one node\nand writing the output file from there."]}),"\n",(0,i.jsxs)(t.p,{children:["Just like the ",(0,i.jsx)(t.em,{children:"compute tasks"})," we created above by calling\n",(0,i.jsx)(t.code,{children:"celerity::handler::parallel_for"}),", we can instantiate a host task on the command group\nhandler by calling ",(0,i.jsx)(t.code,{children:"celerity::handler::host_task"}),". Add the following code at the end of\nyour ",(0,i.jsx)(t.code,{children:"main()"})," function:"]}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-cpp",children:'queue.submit([&](celerity::handler& cgh) {\n\tcelerity::accessor out{edge_buf, cgh, celerity::access::all{}, celerity::read_only_host_task};\n    cgh.host_task(celerity::on_master_node, [=]() {\n        stbi_write_png("result.png", img_width, img_height, 1, out.get_pointer(), 0);\n    });\n});\n'})}),"\n",(0,i.jsxs)(t.p,{children:["Just as in compute kernel command groups, we first obtain accessors for the\nbuffers we want to operate on within this task. Since we need access\nto the entire buffer, we pass an instance of the ",(0,i.jsx)(t.code,{children:"all"})," range mapper."]}),"\n",(0,i.jsxs)(t.p,{children:["Then we supply the code to be run on the host as a lambda function to\n",(0,i.jsx)(t.code,{children:"celerity::handler::host_task"}),". As the tag ",(0,i.jsx)(t.code,{children:"celerity::on_master_node"}),"\nimplies, we select the overload that calls our host task on a single node\n-- the master node. Since the code is executed on the host, we are able to\nuse it for things such as result verification and I/O. In this case, we call\n",(0,i.jsx)(t.code,{children:"stbi_write_png"})," to write our resulting image into a file called ",(0,i.jsx)(t.code,{children:"result.png"}),"."]}),"\n",(0,i.jsxs)(t.blockquote,{children:["\n",(0,i.jsxs)(t.p,{children:[(0,i.jsx)(t.strong,{children:"Note:"})," While master-node tasks are easy to use, they do not scale\nto larger problems. For real-world applications, transferring all data\nto a single node may be either prohibitively expensive or impossible\naltogether. Instead, ",(0,i.jsx)(t.em,{children:"collective host tasks"})," can be used to perform distributed\nI/O with libraries like HDF5. This feature is currently experimental."]}),"\n"]}),"\n",(0,i.jsx)(t.h2,{id:"running-the-application",children:"Running The Application"}),"\n",(0,i.jsx)(t.p,{children:"After you've built the executable, you can try and run it by passing an image\nfile as a command line argument like so:"}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{children:"./edge_detection ./my_image.jpg\n"})}),"\n",(0,i.jsxs)(t.p,{children:["If all goes well, a result file named ",(0,i.jsx)(t.code,{children:"result.png"})," should then be located in\nyour working directory."]}),"\n",(0,i.jsx)(t.p,{children:"Since Celerity applications are built on top of MPI internally, you can now\nalso try and run multiple nodes:"}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{children:"mpirun -n 4 edge_detection ./my_image.jpg\n"})})]})}function h(e={}){const{wrapper:t}={...(0,r.R)(),...e.components};return t?(0,i.jsx)(t,{...e,children:(0,i.jsx)(d,{...e})}):d(e)}},6569:(e,t,n)=>{n.d(t,{A:()=>i});const i=n.p+"assets/images/tutorial_edge_detection_flower_by_reinhold_moeller-7cf45079b86185486b11a6c36f168c54.jpg"},8453:(e,t,n)=>{n.d(t,{R:()=>a,x:()=>s});var i=n(6540);const r={},o=i.createContext(r);function a(e){const t=i.useContext(o);return i.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function s(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:a(e.components),i.createElement(o.Provider,{value:t},e.children)}}}]);